{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d7f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50777f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60537fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain \"langchain[anthropic]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816357bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c412e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad5ebd7",
   "metadata": {},
   "source": [
    "## Building Basic Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796f0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in Bengali.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b8c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool,ToolRuntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fb5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873b43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef83c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cf221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ca5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "739a50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='আমি ভালো আছি, ধন্যবাদ।' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 47, 'total_tokens': 75, 'completion_time': 0.035262896, 'completion_tokens_details': None, 'prompt_time': 0.0022946, 'prompt_tokens_details': None, 'queue_time': 0.05651787, 'total_time': 0.037557496}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--87a4a114-bf74-4c7f-ab73-42badc05a197-0' usage_metadata={'input_tokens': 47, 'output_tokens': 28, 'total_tokens': 75}\n"
     ]
    }
   ],
   "source": [
    "result=model.invoke(\"Hello, how are you? Answer me in bengali\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ff0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "আমি ভালো আছি, ধন্যবাদ।\n"
     ]
    }
   ],
   "source": [
    "print(list(result)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "513d3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11fe50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4c1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68db020a",
   "metadata": {},
   "source": [
    "## Building The Main Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44e8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "141fce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7696830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_weather_for_location,get_user_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bf1bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thred_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses=agent.invoke(\n",
    "    {\n",
    "        \"messages\":[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the weather like in New York?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    "\n",
    ")\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a40b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"I'm not sure, but I can try to forecast a response for you!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# SYSTEM PROMPT\n",
    "# -------------------------\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in english.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CONTEXT SCHEMA\n",
    "# -------------------------\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TOOL DEFINITIONS\n",
    "# -------------------------\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# GROQ MODEL\n",
    "# -------------------------\n",
    "\n",
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",   # You can change to any Groq LLM\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# STRUCTURED OUTPUT FORMAT\n",
    "# -------------------------\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    punny_response: str\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MEMORY CHECKPOINT\n",
    "# -------------------------\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CREATE AGENT\n",
    "# -------------------------\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RUN AGENT - FIRST REQUEST\n",
    "# -------------------------\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response[\"structured_response\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb0e3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"Looks like you're in the Sunshine State! I'm forecasting partly cloudy skies with a high of 78 and a low of 62.\", weather_conditions='partly cloudy skies with a high of 78 and a low of 62.')\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Florida\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06911f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[get_user_location,get_weather_for_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538e3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0683fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9b09e",
   "metadata": {},
   "source": [
    "Structured output\n",
    "Models can be requested to provide their response in a format matching a given schema. This is useful for ensuring the output can be easily parsed and used in subsequent processing. LangChain supports multiple schema types and methods for enforcing structured output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df26987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b1bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6836fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie(BaseModel):\n",
    "    \"\"\"Movie model\"\"\"\n",
    "    title: str = Field(..., description=\"Title of the movie\")\n",
    "    year: int = Field(..., description=\"Year of the movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3a636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_structure=model.with_structured_output(Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Inception' year=2010\n"
     ]
    }
   ],
   "source": [
    "response=model_with_structure.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Provide details about the movie Inception\"}]}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d43a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Inception' year=2010 director='Christopher Nolan' rating=8.8\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    year: int = Field(..., description=\"The year the movie was released\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    rating: float = Field(..., description=\"The movie's rating out of 10\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(Movie)\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "print(response)  # Movie(title=\"Inception\", year=2010, director=\"Christopher Nolan\", rating=8.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d5a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
